{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data',one_hot='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX=mnist.train.images\n",
    "trainY=mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX=mnist.test.images\n",
    "testY=mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path='/tmp/dnn/relu/v6'\n",
    "learning_rate=0.003\n",
    "n_features=trainX.shape[1]\n",
    "n_classes=trainY.shape[1]\n",
    "model_name= 'mnist.ckpt'\n",
    "training_epochs=60\n",
    "batch_size=100\n",
    "K=200\n",
    "L=200\n",
    "M=60\n",
    "N=30\n",
    "\n",
    "training_keep=0.75\n",
    "test_keep=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x=tf.placeholder(tf.float32,shape=[None,n_features],name='input')\n",
    "    y_=tf.placeholder(tf.float32,shape=[None,n_classes],name='output')\n",
    "    pkeep=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer1'):\n",
    "    W1=tf.Variable(tf.truncated_normal([n_features,K],stddev=0.1))\n",
    "    b1=tf.Variable(tf.zeros([K])) \n",
    "    Y1=tf.nn.relu(tf.add(tf.matmul(x,W1),b1))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer2'):\n",
    "    W2=tf.Variable(tf.truncated_normal([K,L],stddev=0.1))\n",
    "    b2=tf.Variable(tf.zeros([L])) \n",
    "    Y2=tf.nn.relu(tf.add(tf.matmul(Y1,W2),b2))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer3'):\n",
    "    W3=tf.Variable(tf.truncated_normal([L,M],stddev=0.1))\n",
    "    b3=tf.Variable(tf.zeros([M])) \n",
    "    Y3=tf.nn.relu(tf.add(tf.matmul(Y2,W3),b3))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('layer4'):\n",
    "    W4=tf.Variable(tf.truncated_normal([M,N],stddev=0.1))\n",
    "    b4=tf.Variable(tf.zeros([N])) \n",
    "    Y4=tf.nn.relu(tf.add(tf.matmul(Y3,W4),b4)) \n",
    "    Y4d=tf.nn.dropout(Y4,pkeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "with tf.name_scope('output'):\n",
    "    W5=tf.Variable(tf.truncated_normal([N,n_classes],stddev=0.1))\n",
    "    b5=tf.Variable(tf.zeros([n_classes]))\n",
    "    Ylogits=tf.matmul(Y4d,W5)+b5\n",
    "    y=tf.nn.softmax(tf.add(tf.matmul(Y4d,W5),b5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy=tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits,labels=y_)\n",
    "    cross_entropy=tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "with tf.name_scope('train'):\n",
    "    train_op=tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    prediction=tf.argmax(y,1,name='prediction')\n",
    "    correct_prediction=tf.equal(prediction,tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss and accuracy logging\n",
    "training_loss=tf.summary.scalar('training_loss',cross_entropy)\n",
    "training_accuracy=tf.summary.scalar('training_accuracy',accuracy)\n",
    "test_loss=tf.summary.scalar('test_loss',cross_entropy)\n",
    "test_accuracy=tf.summary.scalar('test_accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create saver to save the model\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "test_accuracy 0.9501\n",
      "epoch 5\n",
      "test_accuracy 0.9762\n",
      "epoch 10\n",
      "test_accuracy 0.9755\n",
      "epoch 15\n",
      "test_accuracy 0.9767\n",
      "epoch 20\n",
      "test_accuracy 0.9787\n",
      "epoch 25\n",
      "test_accuracy 0.9801\n",
      "epoch 30\n",
      "test_accuracy 0.9809\n",
      "epoch 35\n",
      "test_accuracy 0.9814\n",
      "epoch 40\n",
      "test_accuracy 0.9808\n",
      "epoch 45\n",
      "test_accuracy 0.9787\n",
      "epoch 50\n",
      "test_accuracy 0.9764\n",
      "epoch 55\n",
      "test_accuracy 0.9766\n"
     ]
    }
   ],
   "source": [
    "# execute the graph now\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer=tf.summary.FileWriter(logs_path,graph=tf.get_default_graph())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        batch_count=int(trainX.shape[0]/batch_size)\n",
    "        for i in range(batch_count):\n",
    "            batch_x=trainX[i*batch_size:i*batch_size+batch_size]\n",
    "            batch_y=trainY[i*batch_size:i*batch_size+batch_size]\n",
    "            \n",
    "            _,acc,loss=sess.run([train_op,training_accuracy,training_loss],feed_dict={x:batch_x,y_:batch_y,pkeep:training_keep})\n",
    "            writer.add_summary(loss,epoch * batch_count + i)\n",
    "            writer.add_summary(acc,epoch * batch_count + i)\n",
    "        acc,loss=sess.run([test_accuracy,test_loss],feed_dict={x:testX,y_:testY,pkeep:test_keep})\n",
    "        writer.add_summary(loss,epoch * batch_count + i)\n",
    "        writer.add_summary(acc,epoch * batch_count + i)\n",
    "        \n",
    "        if epoch%5==0:\n",
    "            print('epoch',epoch)\n",
    "            print('test_accuracy',accuracy.eval(feed_dict={x:testX,y_:testY,pkeep:test_keep}))\n",
    "        \n",
    "    saver.save(sess, logs_path + '/' + model_name)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
